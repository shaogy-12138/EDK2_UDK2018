diff --git a/rgb2rgb_template.c b/rgb2rgb_template.c
index ffbf2c7..7361901 100644
--- a/rgb2rgb_template.c
+++ b/rgb2rgb_template.c
@@ -92,12 +92,12 @@ static inline void RENAME(rgb24to32)(const uint8_t *src, uint8_t *dst, long src_
     #endif
     end = s + src_size;
     #ifdef HAVE_MMX
-        asm volatile(PREFETCH"    %0"::"m"(*s):"memory");
+        __asm__ volatile(PREFETCH"    %0"::"m"(*s):"memory");
         mm_end = end - 23;
-        asm volatile("movq        %0, %%mm7"::"m"(mask32):"memory");
+        __asm__ volatile("movq        %0, %%mm7"::"m"(mask32):"memory");
         while (s < mm_end)
         {
-            asm volatile(
+            __asm__ volatile(
             PREFETCH"    32%1           \n\t"
             "movd          %1, %%mm0    \n\t"
             "punpckldq    3%1, %%mm0    \n\t"
@@ -121,8 +121,8 @@ static inline void RENAME(rgb24to32)(const uint8_t *src, uint8_t *dst, long src_
             dest += 32;
             s += 24;
         }
-        asm volatile(SFENCE:::"memory");
-        asm volatile(EMMS:::"memory");
+        __asm__ volatile(SFENCE:::"memory");
+        __asm__ volatile(EMMS:::"memory");
     #endif
     while (s < end)
     {
@@ -152,11 +152,11 @@ static inline void RENAME(rgb32to24)(const uint8_t *src, uint8_t *dst, long src_
 #endif
     end = s + src_size;
 #ifdef HAVE_MMX
-    asm volatile(PREFETCH"    %0"::"m"(*s):"memory");
+    __asm__ volatile(PREFETCH"    %0"::"m"(*s):"memory");
     mm_end = end - 31;
     while (s < mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"    32%1           \n\t"
         "movq          %1, %%mm0    \n\t"
         "movq         8%1, %%mm1    \n\t"
@@ -207,8 +207,8 @@ static inline void RENAME(rgb32to24)(const uint8_t *src, uint8_t *dst, long src_
         dest += 24;
         s += 32;
     }
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     while (s < end)
     {
@@ -242,12 +242,12 @@ static inline void RENAME(rgb15to16)(const uint8_t *src, uint8_t *dst, long src_
     const uint8_t *mm_end;
     end = s + src_size;
 #ifdef HAVE_MMX
-    asm volatile(PREFETCH"    %0"::"m"(*s));
-    asm volatile("movq        %0, %%mm4"::"m"(mask15s));
+    __asm__ volatile(PREFETCH"    %0"::"m"(*s));
+    __asm__ volatile("movq        %0, %%mm4"::"m"(mask15s));
     mm_end = end - 15;
     while (s<mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"  32%1         \n\t"
         "movq        %1, %%mm0  \n\t"
         "movq       8%1, %%mm2  \n\t"
@@ -265,8 +265,8 @@ static inline void RENAME(rgb15to16)(const uint8_t *src, uint8_t *dst, long src_
         d+=16;
         s+=16;
     }
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     mm_end = end - 3;
     while (s < mm_end)
@@ -291,13 +291,13 @@ static inline void RENAME(rgb16to15)(const uint8_t *src, uint8_t *dst, long src_
     const uint8_t *mm_end;
     end = s + src_size;
 #ifdef HAVE_MMX
-    asm volatile(PREFETCH"    %0"::"m"(*s));
-    asm volatile("movq        %0, %%mm7"::"m"(mask15rg));
-    asm volatile("movq        %0, %%mm6"::"m"(mask15b));
+    __asm__ volatile(PREFETCH"    %0"::"m"(*s));
+    __asm__ volatile("movq        %0, %%mm7"::"m"(mask15rg));
+    __asm__ volatile("movq        %0, %%mm6"::"m"(mask15b));
     mm_end = end - 15;
     while (s<mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"  32%1         \n\t"
         "movq        %1, %%mm0  \n\t"
         "movq       8%1, %%mm2  \n\t"
@@ -319,8 +319,8 @@ static inline void RENAME(rgb16to15)(const uint8_t *src, uint8_t *dst, long src_
         d+=16;
         s+=16;
     }
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     mm_end = end - 3;
     while (s < mm_end)
@@ -351,7 +351,7 @@ static inline void RENAME(rgb32to16)(const uint8_t *src, uint8_t *dst, long src_
 #ifdef HAVE_MMX
     mm_end = end - 15;
 #if 1 //is faster only if multiplies are reasonably fast (FIXME figure out on which CPUs this is faster, on Athlon it is slightly faster)
-    asm volatile(
+    __asm__ volatile(
     "movq           %3, %%mm5   \n\t"
     "movq           %4, %%mm6   \n\t"
     "movq           %5, %%mm7   \n\t"
@@ -386,14 +386,14 @@ static inline void RENAME(rgb32to16)(const uint8_t *src, uint8_t *dst, long src_
     : "r" (mm_end), "m" (mask3216g), "m" (mask3216br), "m" (mul3216)
     );
 #else
-    asm volatile(PREFETCH"    %0"::"m"(*src):"memory");
-    asm volatile(
+    __asm__ volatile(PREFETCH"    %0"::"m"(*src):"memory");
+    __asm__ volatile(
         "movq    %0, %%mm7    \n\t"
         "movq    %1, %%mm6    \n\t"
         ::"m"(red_16mask),"m"(green_16mask));
     while (s < mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"    32%1           \n\t"
         "movd          %1, %%mm0    \n\t"
         "movd         4%1, %%mm3    \n\t"
@@ -427,8 +427,8 @@ static inline void RENAME(rgb32to16)(const uint8_t *src, uint8_t *dst, long src_
         s += 16;
     }
 #endif
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     while (s < end)
     {
@@ -447,15 +447,15 @@ static inline void RENAME(rgb32tobgr16)(const uint8_t *src, uint8_t *dst, long s
     uint16_t *d = (uint16_t *)dst;
     end = s + src_size;
 #ifdef HAVE_MMX
-    asm volatile(PREFETCH"    %0"::"m"(*src):"memory");
-    asm volatile(
+    __asm__ volatile(PREFETCH"    %0"::"m"(*src):"memory");
+    __asm__ volatile(
         "movq          %0, %%mm7    \n\t"
         "movq          %1, %%mm6    \n\t"
         ::"m"(red_16mask),"m"(green_16mask));
     mm_end = end - 15;
     while (s < mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"    32%1           \n\t"
         "movd          %1, %%mm0    \n\t"
         "movd         4%1, %%mm3    \n\t"
@@ -488,8 +488,8 @@ static inline void RENAME(rgb32tobgr16)(const uint8_t *src, uint8_t *dst, long s
         d += 4;
         s += 16;
     }
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     while (s < end)
     {
@@ -510,7 +510,7 @@ static inline void RENAME(rgb32to15)(const uint8_t *src, uint8_t *dst, long src_
 #ifdef HAVE_MMX
     mm_end = end - 15;
 #if 1 //is faster only if multiplies are reasonably fast (FIXME figure out on which CPUs this is faster, on Athlon it is slightly faster)
-    asm volatile(
+    __asm__ volatile(
     "movq           %3, %%mm5   \n\t"
     "movq           %4, %%mm6   \n\t"
     "movq           %5, %%mm7   \n\t"
@@ -545,14 +545,14 @@ static inline void RENAME(rgb32to15)(const uint8_t *src, uint8_t *dst, long src_
     : "r" (mm_end), "m" (mask3215g), "m" (mask3216br), "m" (mul3215)
     );
 #else
-    asm volatile(PREFETCH"    %0"::"m"(*src):"memory");
-    asm volatile(
+    __asm__ volatile(PREFETCH"    %0"::"m"(*src):"memory");
+    __asm__ volatile(
         "movq          %0, %%mm7    \n\t"
         "movq          %1, %%mm6    \n\t"
         ::"m"(red_15mask),"m"(green_15mask));
     while (s < mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"    32%1           \n\t"
         "movd          %1, %%mm0    \n\t"
         "movd         4%1, %%mm3    \n\t"
@@ -586,8 +586,8 @@ static inline void RENAME(rgb32to15)(const uint8_t *src, uint8_t *dst, long src_
         s += 16;
     }
 #endif
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     while (s < end)
     {
@@ -606,15 +606,15 @@ static inline void RENAME(rgb32tobgr15)(const uint8_t *src, uint8_t *dst, long s
     uint16_t *d = (uint16_t *)dst;
     end = s + src_size;
 #ifdef HAVE_MMX
-    asm volatile(PREFETCH"    %0"::"m"(*src):"memory");
-    asm volatile(
+    __asm__ volatile(PREFETCH"    %0"::"m"(*src):"memory");
+    __asm__ volatile(
         "movq          %0, %%mm7    \n\t"
         "movq          %1, %%mm6    \n\t"
         ::"m"(red_15mask),"m"(green_15mask));
     mm_end = end - 15;
     while (s < mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"    32%1           \n\t"
         "movd          %1, %%mm0    \n\t"
         "movd         4%1, %%mm3    \n\t"
@@ -647,8 +647,8 @@ static inline void RENAME(rgb32tobgr15)(const uint8_t *src, uint8_t *dst, long s
         d += 4;
         s += 16;
     }
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     while (s < end)
     {
@@ -667,15 +667,15 @@ static inline void RENAME(rgb24to16)(const uint8_t *src, uint8_t *dst, long src_
     uint16_t *d = (uint16_t *)dst;
     end = s + src_size;
 #ifdef HAVE_MMX
-    asm volatile(PREFETCH"    %0"::"m"(*src):"memory");
-    asm volatile(
+    __asm__ volatile(PREFETCH"    %0"::"m"(*src):"memory");
+    __asm__ volatile(
         "movq         %0, %%mm7     \n\t"
         "movq         %1, %%mm6     \n\t"
         ::"m"(red_16mask),"m"(green_16mask));
     mm_end = end - 11;
     while (s < mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"    32%1           \n\t"
         "movd          %1, %%mm0    \n\t"
         "movd         3%1, %%mm3    \n\t"
@@ -708,8 +708,8 @@ static inline void RENAME(rgb24to16)(const uint8_t *src, uint8_t *dst, long src_
         d += 4;
         s += 12;
     }
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     while (s < end)
     {
@@ -730,15 +730,15 @@ static inline void RENAME(rgb24tobgr16)(const uint8_t *src, uint8_t *dst, long s
     uint16_t *d = (uint16_t *)dst;
     end = s + src_size;
 #ifdef HAVE_MMX
-    asm volatile(PREFETCH"    %0"::"m"(*src):"memory");
-    asm volatile(
+    __asm__ volatile(PREFETCH"    %0"::"m"(*src):"memory");
+    __asm__ volatile(
         "movq         %0, %%mm7     \n\t"
         "movq         %1, %%mm6     \n\t"
         ::"m"(red_16mask),"m"(green_16mask));
     mm_end = end - 15;
     while (s < mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"    32%1           \n\t"
         "movd          %1, %%mm0    \n\t"
         "movd         3%1, %%mm3    \n\t"
@@ -771,8 +771,8 @@ static inline void RENAME(rgb24tobgr16)(const uint8_t *src, uint8_t *dst, long s
         d += 4;
         s += 12;
     }
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     while (s < end)
     {
@@ -793,15 +793,15 @@ static inline void RENAME(rgb24to15)(const uint8_t *src, uint8_t *dst, long src_
     uint16_t *d = (uint16_t *)dst;
     end = s + src_size;
 #ifdef HAVE_MMX
-    asm volatile(PREFETCH"    %0"::"m"(*src):"memory");
-    asm volatile(
+    __asm__ volatile(PREFETCH"    %0"::"m"(*src):"memory");
+    __asm__ volatile(
         "movq          %0, %%mm7    \n\t"
         "movq          %1, %%mm6    \n\t"
         ::"m"(red_15mask),"m"(green_15mask));
     mm_end = end - 11;
     while (s < mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"    32%1           \n\t"
         "movd          %1, %%mm0    \n\t"
         "movd         3%1, %%mm3    \n\t"
@@ -834,8 +834,8 @@ static inline void RENAME(rgb24to15)(const uint8_t *src, uint8_t *dst, long src_
         d += 4;
         s += 12;
     }
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     while (s < end)
     {
@@ -856,15 +856,15 @@ static inline void RENAME(rgb24tobgr15)(const uint8_t *src, uint8_t *dst, long s
     uint16_t *d = (uint16_t *)dst;
     end = s + src_size;
 #ifdef HAVE_MMX
-    asm volatile(PREFETCH"    %0"::"m"(*src):"memory");
-    asm volatile(
+    __asm__ volatile(PREFETCH"    %0"::"m"(*src):"memory");
+    __asm__ volatile(
         "movq         %0, %%mm7     \n\t"
         "movq         %1, %%mm6     \n\t"
         ::"m"(red_15mask),"m"(green_15mask));
     mm_end = end - 15;
     while (s < mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"   32%1            \n\t"
         "movd         %1, %%mm0     \n\t"
         "movd        3%1, %%mm3     \n\t"
@@ -897,8 +897,8 @@ static inline void RENAME(rgb24tobgr15)(const uint8_t *src, uint8_t *dst, long s
         d += 4;
         s += 12;
     }
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     while (s < end)
     {
@@ -940,11 +940,11 @@ static inline void RENAME(rgb15to24)(const uint8_t *src, uint8_t *dst, long src_
     const uint16_t *s = (const uint16_t*)src;
     end = s + src_size/2;
 #ifdef HAVE_MMX
-    asm volatile(PREFETCH"    %0"::"m"(*s):"memory");
+    __asm__ volatile(PREFETCH"    %0"::"m"(*s):"memory");
     mm_end = end - 7;
     while (s < mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"    32%1           \n\t"
         "movq          %1, %%mm0    \n\t"
         "movq          %1, %%mm1    \n\t"
@@ -1007,7 +1007,7 @@ static inline void RENAME(rgb15to24)(const uint8_t *src, uint8_t *dst, long src_
         :"m"(*s),"m"(mask15b),"m"(mask15g),"m"(mask15r), "m"(mmx_null)
         :"memory");
         /* borrowed 32 to 24 */
-        asm volatile(
+        __asm__ volatile(
         "movq       %%mm0, %%mm4    \n\t"
         "movq       %%mm3, %%mm5    \n\t"
         "movq       %%mm6, %%mm0    \n\t"
@@ -1059,8 +1059,8 @@ static inline void RENAME(rgb15to24)(const uint8_t *src, uint8_t *dst, long src_
         d += 24;
         s += 8;
     }
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     while (s < end)
     {
@@ -1082,11 +1082,11 @@ static inline void RENAME(rgb16to24)(const uint8_t *src, uint8_t *dst, long src_
     const uint16_t *s = (const uint16_t *)src;
     end = s + src_size/2;
 #ifdef HAVE_MMX
-    asm volatile(PREFETCH"    %0"::"m"(*s):"memory");
+    __asm__ volatile(PREFETCH"    %0"::"m"(*s):"memory");
     mm_end = end - 7;
     while (s < mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"    32%1           \n\t"
         "movq          %1, %%mm0    \n\t"
         "movq          %1, %%mm1    \n\t"
@@ -1148,7 +1148,7 @@ static inline void RENAME(rgb16to24)(const uint8_t *src, uint8_t *dst, long src_
         :"m"(*s),"m"(mask16b),"m"(mask16g),"m"(mask16r),"m"(mmx_null)
         :"memory");
         /* borrowed 32 to 24 */
-        asm volatile(
+        __asm__ volatile(
         "movq       %%mm0, %%mm4    \n\t"
         "movq       %%mm3, %%mm5    \n\t"
         "movq       %%mm6, %%mm0    \n\t"
@@ -1200,8 +1200,8 @@ static inline void RENAME(rgb16to24)(const uint8_t *src, uint8_t *dst, long src_
         d += 24;
         s += 8;
     }
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     while (s < end)
     {
@@ -1223,12 +1223,12 @@ static inline void RENAME(rgb15to32)(const uint8_t *src, uint8_t *dst, long src_
     const uint16_t *s = (const uint16_t *)src;
     end = s + src_size/2;
 #ifdef HAVE_MMX
-    asm volatile(PREFETCH"    %0"::"m"(*s):"memory");
-    asm volatile("pxor    %%mm7,%%mm7    \n\t":::"memory");
+    __asm__ volatile(PREFETCH"    %0"::"m"(*s):"memory");
+    __asm__ volatile("pxor    %%mm7,%%mm7    \n\t":::"memory");
     mm_end = end - 3;
     while (s < mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"    32%1           \n\t"
         "movq          %1, %%mm0    \n\t"
         "movq          %1, %%mm1    \n\t"
@@ -1264,8 +1264,8 @@ static inline void RENAME(rgb15to32)(const uint8_t *src, uint8_t *dst, long src_
         d += 16;
         s += 4;
     }
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     while (s < end)
     {
@@ -1301,12 +1301,12 @@ static inline void RENAME(rgb16to32)(const uint8_t *src, uint8_t *dst, long src_
     const uint16_t *s = (const uint16_t*)src;
     end = s + src_size/2;
 #ifdef HAVE_MMX
-    asm volatile(PREFETCH"    %0"::"m"(*s):"memory");
-    asm volatile("pxor    %%mm7,%%mm7    \n\t":::"memory");
+    __asm__ volatile(PREFETCH"    %0"::"m"(*s):"memory");
+    __asm__ volatile("pxor    %%mm7,%%mm7    \n\t":::"memory");
     mm_end = end - 3;
     while (s < mm_end)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"    32%1           \n\t"
         "movq          %1, %%mm0    \n\t"
         "movq          %1, %%mm1    \n\t"
@@ -1342,8 +1342,8 @@ static inline void RENAME(rgb16to32)(const uint8_t *src, uint8_t *dst, long src_
         d += 16;
         s += 4;
     }
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     while (s < end)
     {
@@ -1369,7 +1369,7 @@ static inline void RENAME(rgb32tobgr32)(const uint8_t *src, uint8_t *dst, long s
     const uint8_t *s = src-idx;
     uint8_t *d = dst-idx;
 #ifdef HAVE_MMX
-    asm volatile(
+    __asm__ volatile(
     "test          %0, %0           \n\t"
     "jns           2f               \n\t"
     PREFETCH"       (%1, %0)        \n\t"
@@ -1432,7 +1432,7 @@ static inline void RENAME(rgb24tobgr24)(const uint8_t *src, uint8_t *dst, long s
     unsigned i;
 #ifdef HAVE_MMX
     long mmx_size= 23 - src_size;
-    asm volatile (
+    __asm__ volatile (
     "test             %%"REG_a", %%"REG_a"          \n\t"
     "jns                     2f                     \n\t"
     "movq     "MANGLE(mask24r)", %%mm5              \n\t"
@@ -1476,8 +1476,8 @@ static inline void RENAME(rgb24tobgr24)(const uint8_t *src, uint8_t *dst, long s
     : "r" (src-mmx_size), "r"(dst-mmx_size)
     );
 
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 
     if (mmx_size==23) return; //finished, was multiple of 8
 
@@ -1507,7 +1507,7 @@ static inline void RENAME(yuvPlanartoyuy2)(const uint8_t *ysrc, const uint8_t *u
     {
 #ifdef HAVE_MMX
 //FIXME handle 2 lines at once (fewer prefetches, reuse some chroma, but very likely memory-limited anyway)
-        asm volatile(
+        __asm__ volatile(
         "xor                 %%"REG_a", %%"REG_a"   \n\t"
         ASMALIGN(4)
         "1:                                         \n\t"
@@ -1548,10 +1548,10 @@ static inline void RENAME(yuvPlanartoyuy2)(const uint8_t *ysrc, const uint8_t *u
     y2 = yc2[n];                    \
     u = uc[n];                      \
     v = vc[n];                      \
-    asm("unpkbw %1, %0" : "=r"(y1) : "r"(y1));  \
-    asm("unpkbw %1, %0" : "=r"(y2) : "r"(y2));  \
-    asm("unpkbl %1, %0" : "=r"(u) : "r"(u));    \
-    asm("unpkbl %1, %0" : "=r"(v) : "r"(v));    \
+    __asm__("unpkbw %1, %0" : "=r"(y1) : "r"(y1));  \
+    __asm__("unpkbw %1, %0" : "=r"(y2) : "r"(y2));  \
+    __asm__("unpkbl %1, %0" : "=r"(u) : "r"(u));    \
+    __asm__("unpkbl %1, %0" : "=r"(v) : "r"(v));    \
     yuv1 = (u << 8) + (v << 24);                \
     yuv2 = yuv1 + y2;               \
     yuv1 += y1;                     \
@@ -1568,10 +1568,10 @@ static inline void RENAME(yuvPlanartoyuy2)(const uint8_t *ysrc, const uint8_t *u
             uint64_t y1, y2, yuv1, yuv2;
             uint64_t u, v;
             /* Prefetch */
-            asm("ldq $31,64(%0)" :: "r"(yc));
-            asm("ldq $31,64(%0)" :: "r"(yc2));
-            asm("ldq $31,64(%0)" :: "r"(uc));
-            asm("ldq $31,64(%0)" :: "r"(vc));
+            __asm__("ldq $31,64(%0)" :: "r"(yc));
+            __asm__("ldq $31,64(%0)" :: "r"(yc2));
+            __asm__("ldq $31,64(%0)" :: "r"(uc));
+            __asm__("ldq $31,64(%0)" :: "r"(vc));
 
             pl2yuy2(0);
             pl2yuy2(1);
@@ -1631,7 +1631,7 @@ static inline void RENAME(yuvPlanartoyuy2)(const uint8_t *ysrc, const uint8_t *u
         dst  += dstStride;
     }
 #ifdef HAVE_MMX
-asm(    EMMS"       \n\t"
+__asm__(    EMMS"       \n\t"
         SFENCE"     \n\t"
         :::"memory");
 #endif
@@ -1659,7 +1659,7 @@ static inline void RENAME(yuvPlanartouyvy)(const uint8_t *ysrc, const uint8_t *u
     {
 #ifdef HAVE_MMX
 //FIXME handle 2 lines at once (fewer prefetches, reuse some chroma, but very likely memory-limited anyway)
-        asm volatile(
+        __asm__ volatile(
         "xor                %%"REG_a", %%"REG_a"    \n\t"
         ASMALIGN(4)
         "1:                                         \n\t"
@@ -1737,7 +1737,7 @@ static inline void RENAME(yuvPlanartouyvy)(const uint8_t *ysrc, const uint8_t *u
         dst += dstStride;
     }
 #ifdef HAVE_MMX
-asm(    EMMS"       \n\t"
+__asm__(    EMMS"       \n\t"
         SFENCE"     \n\t"
         :::"memory");
 #endif
@@ -1778,7 +1778,7 @@ static inline void RENAME(yuy2toyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
     for (y=0; y<height; y+=2)
     {
 #ifdef HAVE_MMX
-        asm volatile(
+        __asm__ volatile(
         "xor                 %%"REG_a", %%"REG_a"   \n\t"
         "pcmpeqw                 %%mm7, %%mm7       \n\t"
         "psrlw                      $8, %%mm7       \n\t" // FF,00,FF,00...
@@ -1833,7 +1833,7 @@ static inline void RENAME(yuy2toyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
         ydst += lumStride;
         src  += srcStride;
 
-        asm volatile(
+        __asm__ volatile(
         "xor                 %%"REG_a", %%"REG_a"   \n\t"
         ASMALIGN(4)
         "1:                                         \n\t"
@@ -1883,7 +1883,7 @@ static inline void RENAME(yuy2toyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
         src  += srcStride;
     }
 #ifdef HAVE_MMX
-asm volatile(   EMMS"       \n\t"
+__asm__ volatile(   EMMS"       \n\t"
                 SFENCE"     \n\t"
                 :::"memory");
 #endif
@@ -1917,7 +1917,7 @@ static inline void RENAME(planar2x)(const uint8_t *src, uint8_t *dst, long srcWi
     for (y=1; y<srcHeight; y++){
 #if defined (HAVE_MMX2) || defined (HAVE_3DNOW)
         const long mmxSize= srcWidth&~15;
-        asm volatile(
+        __asm__ volatile(
         "mov           %4, %%"REG_a"            \n\t"
         "1:                                     \n\t"
         "movq         (%0, %%"REG_a"), %%mm0    \n\t"
@@ -1995,7 +1995,7 @@ static inline void RENAME(planar2x)(const uint8_t *src, uint8_t *dst, long srcWi
 #endif
 
 #ifdef HAVE_MMX
-asm volatile(   EMMS"       \n\t"
+__asm__ volatile(   EMMS"       \n\t"
                 SFENCE"     \n\t"
                 :::"memory");
 #endif
@@ -2016,7 +2016,7 @@ static inline void RENAME(uyvytoyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
     for (y=0; y<height; y+=2)
     {
 #ifdef HAVE_MMX
-        asm volatile(
+        __asm__ volatile(
         "xorl                %%eax, %%eax   \n\t"
         "pcmpeqw             %%mm7, %%mm7   \n\t"
         "psrlw                  $8, %%mm7   \n\t" // FF,00,FF,00...
@@ -2071,7 +2071,7 @@ static inline void RENAME(uyvytoyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
         ydst += lumStride;
         src  += srcStride;
 
-        asm volatile(
+        __asm__ volatile(
         "xorl                %%eax, %%eax   \n\t"
         ASMALIGN(4)
         "1:                                 \n\t"
@@ -2121,7 +2121,7 @@ static inline void RENAME(uyvytoyv12)(const uint8_t *src, uint8_t *ydst, uint8_t
         src  += srcStride;
     }
 #ifdef HAVE_MMX
-asm volatile(   EMMS"       \n\t"
+__asm__ volatile(   EMMS"       \n\t"
                 SFENCE"     \n\t"
                 :::"memory");
 #endif
@@ -2146,7 +2146,7 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
         long i;
         for (i=0; i<2; i++)
         {
-            asm volatile(
+            __asm__ volatile(
             "mov                        %2, %%"REG_a"   \n\t"
             "movq  "MANGLE(ff_bgr2YCoeff)", %%mm6       \n\t"
             "movq       "MANGLE(ff_w1111)", %%mm5       \n\t"
@@ -2219,7 +2219,7 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
             src  += srcStride;
         }
         src -= srcStride*2;
-        asm volatile(
+        __asm__ volatile(
         "mov                        %4, %%"REG_a"   \n\t"
         "movq       "MANGLE(ff_w1111)", %%mm5       \n\t"
         "movq  "MANGLE(ff_bgr2UCoeff)", %%mm6       \n\t"
@@ -2373,7 +2373,7 @@ static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_
         src  += srcStride*2;
     }
 
-    asm volatile(   EMMS"       \n\t"
+    __asm__ volatile(   EMMS"       \n\t"
                     SFENCE"     \n\t"
                     :::"memory");
 #else
@@ -2441,7 +2441,7 @@ void RENAME(interleaveBytes)(uint8_t *src1, uint8_t *src2, uint8_t *dest,
 
 #ifdef HAVE_MMX
 #ifdef HAVE_SSE2
-        asm(
+        __asm__(
         "xor              %%"REG_a", %%"REG_a"  \n\t"
         "1:                                     \n\t"
         PREFETCH" 64(%1, %%"REG_a")             \n\t"
@@ -2460,7 +2460,7 @@ void RENAME(interleaveBytes)(uint8_t *src1, uint8_t *src2, uint8_t *dest,
         : "memory", "%"REG_a""
         );
 #else
-        asm(
+        __asm__(
         "xor %%"REG_a", %%"REG_a"               \n\t"
         "1:                                     \n\t"
         PREFETCH" 64(%1, %%"REG_a")             \n\t"
@@ -2503,7 +2503,7 @@ void RENAME(interleaveBytes)(uint8_t *src1, uint8_t *src2, uint8_t *dest,
                 src2 += src2Stride;
     }
 #ifdef HAVE_MMX
-    asm(
+    __asm__(
         EMMS"       \n\t"
         SFENCE"     \n\t"
         ::: "memory"
@@ -2520,7 +2520,7 @@ static inline void RENAME(vu9_to_vu12)(const uint8_t *src1, const uint8_t *src2,
     long y,x,w,h;
     w=width/2; h=height/2;
 #ifdef HAVE_MMX
-    asm volatile(
+    __asm__ volatile(
     PREFETCH" %0    \n\t"
     PREFETCH" %1    \n\t"
     ::"m"(*(src1+srcStride1)),"m"(*(src2+srcStride2)):"memory");
@@ -2532,7 +2532,7 @@ static inline void RENAME(vu9_to_vu12)(const uint8_t *src1, const uint8_t *src2,
 #ifdef HAVE_MMX
     for (;x<w-31;x+=32)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"   32%1        \n\t"
         "movq         %1, %%mm0 \n\t"
         "movq        8%1, %%mm2 \n\t"
@@ -2572,7 +2572,7 @@ static inline void RENAME(vu9_to_vu12)(const uint8_t *src1, const uint8_t *src2,
 #ifdef HAVE_MMX
     for (;x<w-31;x+=32)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"   32%1        \n\t"
         "movq         %1, %%mm0 \n\t"
         "movq        8%1, %%mm2 \n\t"
@@ -2606,7 +2606,7 @@ static inline void RENAME(vu9_to_vu12)(const uint8_t *src1, const uint8_t *src2,
     for (;x<w;x++) d[2*x]=d[2*x+1]=s2[x];
     }
 #ifdef HAVE_MMX
-    asm(
+    __asm__(
         EMMS"       \n\t"
         SFENCE"     \n\t"
         ::: "memory"
@@ -2631,7 +2631,7 @@ static inline void RENAME(yvu9_to_yuy2)(const uint8_t *src1, const uint8_t *src2
 #ifdef HAVE_MMX
     for (;x<w-7;x+=8)
     {
-        asm volatile(
+        __asm__ volatile(
         PREFETCH"   32(%1, %0)          \n\t"
         PREFETCH"   32(%2, %0)          \n\t"
         PREFETCH"   32(%3, %0)          \n\t"
@@ -2697,7 +2697,7 @@ static inline void RENAME(yvu9_to_yuy2)(const uint8_t *src1, const uint8_t *src2
     }
     }
 #ifdef HAVE_MMX
-    asm(
+    __asm__(
         EMMS"       \n\t"
         SFENCE"     \n\t"
         ::: "memory"
diff --git a/swscale-example.c b/swscale-example.c
index 79e21a9..e29ab92 100644
--- a/swscale-example.c
+++ b/swscale-example.c
@@ -120,7 +120,7 @@ static int doTest(uint8_t *ref[3], int refStride[3], int w, int h, int srcFormat
     sws_scale(outContext, dst, dstStride, 0, dstH, out, refStride);
 
 #if defined(ARCH_X86)
-    asm volatile ("emms\n\t");
+    __asm__ volatile ("emms\n\t");
 #endif
 
     ssdY= getSSD(ref[0], out[0], refStride[0], refStride[0], w, h);
@@ -220,7 +220,7 @@ int main(int argc, char **argv){
     sws_scale(sws, rgb_src, rgb_stride, 0, H, src, stride);
 
 #if defined(ARCH_X86)
-    asm volatile ("emms\n\t");
+    __asm__ volatile ("emms\n\t");
 #endif
 
     selfTest(src, stride, W, H);
diff --git a/swscale.c b/swscale.c
index ccdeae8..8a89678 100644
--- a/swscale.c
+++ b/swscale.c
@@ -61,7 +61,7 @@ untested special converters
 #include <unistd.h>
 #include "config.h"
 #include <assert.h>
-#ifdef HAVE_SYS_MMAN_H
+#if HAVE_SYS_MMAN_H != 0
 #include <sys/mman.h>
 #if defined(MAP_ANON) && !defined(MAP_ANONYMOUS)
 #define MAP_ANONYMOUS MAP_ANON
@@ -935,7 +935,7 @@ static inline int initFilter(int16_t **outFilter, int16_t **filterPos, int *outF
     int ret= -1;
 #if defined(ARCH_X86)
     if (flags & SWS_CPU_CAPS_MMX)
-        asm volatile("emms\n\t"::: "memory"); //FIXME this should not be required but it IS (even for non-MMX versions)
+        __asm__ volatile("emms\n\t"::: "memory"); //FIXME this should not be required but it IS (even for non-MMX versions)
 #endif
 
     // Note the +1 is for the MMXscaler which reads over the end
@@ -1322,7 +1322,7 @@ static void initMMX2HScaler(int dstW, int xInc, uint8_t *funnyCode, int16_t *fil
 
     //code fragment
 
-    asm volatile(
+    __asm__ volatile(
         "jmp                         9f                 \n\t"
     // Begin
         "0:                                             \n\t"
@@ -1362,7 +1362,7 @@ static void initMMX2HScaler(int dstW, int xInc, uint8_t *funnyCode, int16_t *fil
         "=r" (fragmentLengthA)
     );
 
-    asm volatile(
+    __asm__ volatile(
         "jmp                         9f                 \n\t"
     // Begin
         "0:                                             \n\t"
@@ -1978,7 +1978,7 @@ SwsContext *sws_getContext(int srcW, int srcH, int srcFormat, int dstW, int dstH
     SwsFilter dummyFilter= {NULL, NULL, NULL, NULL};
 #if defined(ARCH_X86)
     if (flags & SWS_CPU_CAPS_MMX)
-        asm volatile("emms\n\t"::: "memory");
+        __asm__ volatile("emms\n\t"::: "memory");
 #endif
 
 #if !defined(RUNTIME_CPUDETECT) || !defined (CONFIG_GPL) //ensure that the flags match the compiled variant if cpudetect is off
@@ -1991,7 +1991,7 @@ SwsContext *sws_getContext(int srcW, int srcH, int srcFormat, int dstW, int dstH
     flags |= SWS_CPU_CAPS_MMX;
 #elif defined (HAVE_ALTIVEC)
     flags |= SWS_CPU_CAPS_ALTIVEC;
-#elif defined (ARCH_BFIN)
+#elif ARCH_BFIN
     flags |= SWS_CPU_CAPS_BFIN;
 #endif
 #endif /* RUNTIME_CPUDETECT */
@@ -2204,7 +2204,7 @@ SwsContext *sws_getContext(int srcW, int srcH, int srcFormat, int dstW, int dstH
             c->swScale= gray16swap;
         }
 
-#ifdef ARCH_BFIN
+#if ARCH_BFIN
         if (flags & SWS_CPU_CAPS_BFIN)
             ff_bfin_get_unscaled_swscale (c);
 #endif
diff --git a/swscale_internal.h b/swscale_internal.h
index e904205..38c7fd7 100644
--- a/swscale_internal.h
+++ b/swscale_internal.h
@@ -23,7 +23,7 @@
 
 #include "config.h"
 
-#ifdef HAVE_ALTIVEC_H
+#if HAVE_ALTIVEC_H != 0
 #include <altivec.h>
 #endif
 
@@ -148,7 +148,7 @@ typedef struct SwsContext{
     uint64_t u_temp       __attribute__((aligned(8)));
     uint64_t v_temp       __attribute__((aligned(8)));
 
-#ifdef HAVE_ALTIVEC
+#if HAVE_ALTIVEC != 0
 
   vector signed short   CY;
   vector signed short   CRV;
diff --git a/swscale_template.c b/swscale_template.c
index 1280ba6..b46cc87 100644
--- a/swscale_template.c
+++ b/swscale_template.c
@@ -71,7 +71,7 @@
 #endif
 
 #define YSCALEYUV2YV12X(x, offset, dest, width) \
-    asm volatile(\
+    __asm__ volatile(\
     "xor                          %%"REG_a", %%"REG_a"  \n\t"\
     "movq             "VROUNDER_OFFSET"(%0), %%mm3      \n\t"\
     "movq                             %%mm3, %%mm4      \n\t"\
@@ -107,7 +107,7 @@
     );
 
 #define YSCALEYUV2YV12X_ACCURATE(x, offset, dest, width) \
-    asm volatile(\
+    __asm__ volatile(\
     "lea                     " offset "(%0), %%"REG_d"  \n\t"\
     "xor                          %%"REG_a", %%"REG_a"  \n\t"\
     "pxor                             %%mm4, %%mm4      \n\t"\
@@ -207,7 +207,7 @@
     : "%eax", "%ebx", "%ecx", "%edx", "%esi"
 */
 #define YSCALEYUV2PACKEDX \
-    asm volatile(\
+    __asm__ volatile(\
     "xor                   %%"REG_a", %%"REG_a"     \n\t"\
     ASMALIGN(4)\
     "nop                                            \n\t"\
@@ -256,7 +256,7 @@
     );
 
 #define YSCALEYUV2PACKEDX_ACCURATE \
-    asm volatile(\
+    __asm__ volatile(\
     "xor %%"REG_a", %%"REG_a"                       \n\t"\
     ASMALIGN(4)\
     "nop                                            \n\t"\
@@ -998,7 +998,7 @@ static inline void RENAME(yuv2yuv1)(SwsContext *c, int16_t *lumSrc, int16_t *chr
 
     if (c->flags & SWS_ACCURATE_RND){
         while(p--){
-            asm volatile(
+            __asm__ volatile(
                 YSCALEYUV2YV121_ACCURATE
                 :: "r" (src[p]), "r" (dst[p] + counter[p]),
                 "g" (-counter[p])
@@ -1007,7 +1007,7 @@ static inline void RENAME(yuv2yuv1)(SwsContext *c, int16_t *lumSrc, int16_t *chr
         }
     }else{
         while(p--){
-            asm volatile(
+            __asm__ volatile(
                 YSCALEYUV2YV121
                 :: "r" (src[p]), "r" (dst[p] + counter[p]),
                 "g" (-counter[p])
@@ -1215,7 +1215,7 @@ static inline void RENAME(yuv2packed2)(SwsContext *c, uint16_t *buf0, uint16_t *
         {
 #ifdef HAVE_MMX
         case PIX_FMT_RGB32:
-            asm volatile(
+            __asm__ volatile(
 
 
 FULL_YSCALEYUV2RGB
@@ -1239,7 +1239,7 @@ FULL_YSCALEYUV2RGB
             );
             break;
         case PIX_FMT_BGR24:
-            asm volatile(
+            __asm__ volatile(
 
 FULL_YSCALEYUV2RGB
 
@@ -1288,7 +1288,7 @@ FULL_YSCALEYUV2RGB
             );
             break;
         case PIX_FMT_BGR555:
-            asm volatile(
+            __asm__ volatile(
 
 FULL_YSCALEYUV2RGB
 #ifdef DITHER1XBPP
@@ -1321,7 +1321,7 @@ FULL_YSCALEYUV2RGB
             );
             break;
         case PIX_FMT_BGR565:
-            asm volatile(
+            __asm__ volatile(
 
 FULL_YSCALEYUV2RGB
 #ifdef DITHER1XBPP
@@ -1428,7 +1428,7 @@ FULL_YSCALEYUV2RGB
         {
             //Note 8280 == DSTW_OFFSET but the preprocessor can't handle that there :(
             case PIX_FMT_RGB32:
-                asm volatile(
+                __asm__ volatile(
                 "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
                 "mov        %4, %%"REG_b"               \n\t"
                 "push %%"REG_BP"                        \n\t"
@@ -1442,7 +1442,7 @@ FULL_YSCALEYUV2RGB
                 );
                 return;
             case PIX_FMT_BGR24:
-                asm volatile(
+                __asm__ volatile(
                 "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
                 "mov        %4, %%"REG_b"               \n\t"
                 "push %%"REG_BP"                        \n\t"
@@ -1455,7 +1455,7 @@ FULL_YSCALEYUV2RGB
                 );
                 return;
             case PIX_FMT_BGR555:
-                asm volatile(
+                __asm__ volatile(
                 "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
                 "mov        %4, %%"REG_b"               \n\t"
                 "push %%"REG_BP"                        \n\t"
@@ -1476,7 +1476,7 @@ FULL_YSCALEYUV2RGB
                 );
                 return;
             case PIX_FMT_BGR565:
-                asm volatile(
+                __asm__ volatile(
                 "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
                 "mov        %4, %%"REG_b"               \n\t"
                 "push %%"REG_BP"                        \n\t"
@@ -1496,7 +1496,7 @@ FULL_YSCALEYUV2RGB
                 );
                 return;
             case PIX_FMT_YUYV422:
-                asm volatile(
+                __asm__ volatile(
                 "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
                 "mov %4, %%"REG_b"                        \n\t"
                 "push %%"REG_BP"                        \n\t"
@@ -1538,7 +1538,7 @@ static inline void RENAME(yuv2packed1)(SwsContext *c, uint16_t *buf0, uint16_t *
         switch(dstFormat)
         {
         case PIX_FMT_RGB32:
-            asm volatile(
+            __asm__ volatile(
             "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
             "mov        %4, %%"REG_b"               \n\t"
             "push %%"REG_BP"                        \n\t"
@@ -1552,7 +1552,7 @@ static inline void RENAME(yuv2packed1)(SwsContext *c, uint16_t *buf0, uint16_t *
             );
             return;
         case PIX_FMT_BGR24:
-            asm volatile(
+            __asm__ volatile(
             "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
             "mov        %4, %%"REG_b"               \n\t"
             "push %%"REG_BP"                        \n\t"
@@ -1566,7 +1566,7 @@ static inline void RENAME(yuv2packed1)(SwsContext *c, uint16_t *buf0, uint16_t *
             );
             return;
         case PIX_FMT_BGR555:
-            asm volatile(
+            __asm__ volatile(
             "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
             "mov        %4, %%"REG_b"               \n\t"
             "push %%"REG_BP"                        \n\t"
@@ -1586,7 +1586,7 @@ static inline void RENAME(yuv2packed1)(SwsContext *c, uint16_t *buf0, uint16_t *
             );
             return;
         case PIX_FMT_BGR565:
-            asm volatile(
+            __asm__ volatile(
             "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
             "mov        %4, %%"REG_b"               \n\t"
             "push %%"REG_BP"                        \n\t"
@@ -1607,7 +1607,7 @@ static inline void RENAME(yuv2packed1)(SwsContext *c, uint16_t *buf0, uint16_t *
             );
             return;
         case PIX_FMT_YUYV422:
-            asm volatile(
+            __asm__ volatile(
             "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
             "mov        %4, %%"REG_b"               \n\t"
             "push %%"REG_BP"                        \n\t"
@@ -1627,7 +1627,7 @@ static inline void RENAME(yuv2packed1)(SwsContext *c, uint16_t *buf0, uint16_t *
         switch(dstFormat)
         {
         case PIX_FMT_RGB32:
-            asm volatile(
+            __asm__ volatile(
             "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
             "mov        %4, %%"REG_b"               \n\t"
             "push %%"REG_BP"                        \n\t"
@@ -1641,7 +1641,7 @@ static inline void RENAME(yuv2packed1)(SwsContext *c, uint16_t *buf0, uint16_t *
             );
             return;
         case PIX_FMT_BGR24:
-            asm volatile(
+            __asm__ volatile(
             "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
             "mov        %4, %%"REG_b"               \n\t"
             "push %%"REG_BP"                        \n\t"
@@ -1655,7 +1655,7 @@ static inline void RENAME(yuv2packed1)(SwsContext *c, uint16_t *buf0, uint16_t *
             );
             return;
         case PIX_FMT_BGR555:
-            asm volatile(
+            __asm__ volatile(
             "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
             "mov        %4, %%"REG_b"               \n\t"
             "push %%"REG_BP"                        \n\t"
@@ -1675,7 +1675,7 @@ static inline void RENAME(yuv2packed1)(SwsContext *c, uint16_t *buf0, uint16_t *
             );
             return;
         case PIX_FMT_BGR565:
-            asm volatile(
+            __asm__ volatile(
             "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
             "mov        %4, %%"REG_b"               \n\t"
             "push %%"REG_BP"                        \n\t"
@@ -1696,7 +1696,7 @@ static inline void RENAME(yuv2packed1)(SwsContext *c, uint16_t *buf0, uint16_t *
             );
             return;
         case PIX_FMT_YUYV422:
-            asm volatile(
+            __asm__ volatile(
             "mov %%"REG_b", "ESP_OFFSET"(%5)        \n\t"
             "mov        %4, %%"REG_b"               \n\t"
             "push %%"REG_BP"                        \n\t"
@@ -1725,7 +1725,7 @@ static inline void RENAME(yuv2packed1)(SwsContext *c, uint16_t *buf0, uint16_t *
 static inline void RENAME(yuy2ToY)(uint8_t *dst, uint8_t *src, long width)
 {
 #ifdef HAVE_MMX
-    asm volatile(
+    __asm__ volatile(
     "movq "MANGLE(bm01010101)", %%mm2           \n\t"
     "mov                    %0, %%"REG_a"       \n\t"
     "1:                                         \n\t"
@@ -1750,7 +1750,7 @@ static inline void RENAME(yuy2ToY)(uint8_t *dst, uint8_t *src, long width)
 static inline void RENAME(yuy2ToUV)(uint8_t *dstU, uint8_t *dstV, uint8_t *src1, uint8_t *src2, long width)
 {
 #ifdef HAVE_MMX
-    asm volatile(
+    __asm__ volatile(
     "movq "MANGLE(bm01010101)", %%mm4           \n\t"
     "mov                    %0, %%"REG_a"       \n\t"
     "1:                                         \n\t"
@@ -1787,7 +1787,7 @@ static inline void RENAME(yuy2ToUV)(uint8_t *dstU, uint8_t *dstV, uint8_t *src1,
 static inline void RENAME(uyvyToY)(uint8_t *dst, uint8_t *src, long width)
 {
 #ifdef HAVE_MMX
-    asm volatile(
+    __asm__ volatile(
     "mov                  %0, %%"REG_a"         \n\t"
     "1:                                         \n\t"
     "movq  (%1, %%"REG_a",2), %%mm0             \n\t"
@@ -1811,7 +1811,7 @@ static inline void RENAME(uyvyToY)(uint8_t *dst, uint8_t *src, long width)
 static inline void RENAME(uyvyToUV)(uint8_t *dstU, uint8_t *dstV, uint8_t *src1, uint8_t *src2, long width)
 {
 #ifdef HAVE_MMX
-    asm volatile(
+    __asm__ volatile(
     "movq "MANGLE(bm01010101)", %%mm4           \n\t"
     "mov                    %0, %%"REG_a"       \n\t"
     "1:                                         \n\t"
@@ -1878,7 +1878,7 @@ static inline void RENAME(bgr32ToUV)(uint8_t *dstU, uint8_t *dstV, uint8_t *src1
 static inline void RENAME(bgr24ToY)(uint8_t *dst, uint8_t *src, long width)
 {
 #ifdef HAVE_MMX
-    asm volatile(
+    __asm__ volatile(
     "mov                        %2, %%"REG_a"   \n\t"
     "movq  "MANGLE(ff_bgr2YCoeff)", %%mm6       \n\t"
     "movq       "MANGLE(ff_w1111)", %%mm5       \n\t"
@@ -1963,7 +1963,7 @@ static inline void RENAME(bgr24ToY)(uint8_t *dst, uint8_t *src, long width)
 static inline void RENAME(bgr24ToUV)(uint8_t *dstU, uint8_t *dstV, uint8_t *src1, uint8_t *src2, long width)
 {
 #ifdef HAVE_MMX
-    asm volatile(
+    __asm__ volatile(
     "mov                        %3, %%"REG_a"   \n\t"
     "movq       "MANGLE(ff_w1111)", %%mm5       \n\t"
     "movq  "MANGLE(ff_bgr2UCoeff)", %%mm6       \n\t"
@@ -2329,7 +2329,7 @@ static inline void RENAME(hScale)(int16_t *dst, int dstW, uint8_t *src, int srcW
         filter-= counter*2;
         filterPos-= counter/2;
         dst-= counter/2;
-        asm volatile(
+        __asm__ volatile(
 #if defined(PIC)
         "push            %%"REG_b"              \n\t"
 #endif
@@ -2375,7 +2375,7 @@ static inline void RENAME(hScale)(int16_t *dst, int dstW, uint8_t *src, int srcW
         filter-= counter*4;
         filterPos-= counter/2;
         dst-= counter/2;
-        asm volatile(
+        __asm__ volatile(
 #if defined(PIC)
         "push             %%"REG_b"             \n\t"
 #endif
@@ -2434,7 +2434,7 @@ static inline void RENAME(hScale)(int16_t *dst, int dstW, uint8_t *src, int srcW
         //filter-= counter*filterSize/2;
         filterPos-= counter/2;
         dst-= counter/2;
-        asm volatile(
+        __asm__ volatile(
         "pxor                  %%mm7, %%mm7     \n\t"
         "movq          "MANGLE(w02)", %%mm6     \n\t"
         ASMALIGN(4)
@@ -2564,7 +2564,7 @@ static inline void RENAME(hyscale)(uint16_t *dst, long dstWidth, uint8_t *src, i
     }
 
 #ifdef HAVE_MMX
-    // Use the new MMX scaler if the MMX2 one can't be used (it is faster than the x86 ASM one).
+    // Use the new MMX scaler if the MMX2 one can't be used (it is faster than the x86 __asm__ one).
     if (!(flags&SWS_FAST_BILINEAR) || (!canMMX2BeUsed))
 #else
     if (!(flags&SWS_FAST_BILINEAR))
@@ -2582,7 +2582,7 @@ static inline void RENAME(hyscale)(uint16_t *dst, long dstWidth, uint8_t *src, i
 #endif
         if (canMMX2BeUsed)
         {
-            asm volatile(
+            __asm__ volatile(
 #if defined(PIC)
             "mov               %%"REG_b", %5        \n\t"
 #endif
@@ -2646,8 +2646,8 @@ FUNNY_Y_CODE
 #endif /* HAVE_MMX2 */
         long xInc_shr16 = xInc >> 16;
         uint16_t xInc_mask = xInc & 0xffff;
-        //NO MMX just normal asm ...
-        asm volatile(
+        //NO MMX just normal __asm__ ...
+        __asm__ volatile(
         "xor %%"REG_a", %%"REG_a"            \n\t" // i
         "xor %%"REG_d", %%"REG_d"            \n\t" // xx
         "xorl    %%ecx, %%ecx                \n\t" // 2*xalpha
@@ -2781,7 +2781,7 @@ inline static void RENAME(hcscale)(uint16_t *dst, long dstWidth, uint8_t *src1,
     }
 
 #ifdef HAVE_MMX
-    // Use the new MMX scaler if the MMX2 one can't be used (it is faster than the x86 ASM one).
+    // Use the new MMX scaler if the MMX2 one can't be used (it is faster than the x86 __asm__ one).
     if (!(flags&SWS_FAST_BILINEAR) || (!canMMX2BeUsed))
 #else
     if (!(flags&SWS_FAST_BILINEAR))
@@ -2800,7 +2800,7 @@ inline static void RENAME(hcscale)(uint16_t *dst, long dstWidth, uint8_t *src1,
 #endif
         if (canMMX2BeUsed)
         {
-            asm volatile(
+            __asm__ volatile(
 #if defined(PIC)
             "mov          %%"REG_b", %6         \n\t"
 #endif
@@ -2877,7 +2877,7 @@ FUNNY_UV_CODE
 #endif /* HAVE_MMX2 */
             long xInc_shr16 = (long) (xInc >> 16);
             uint16_t xInc_mask = xInc & 0xffff;
-            asm volatile(
+            __asm__ volatile(
             "xor %%"REG_a", %%"REG_a"               \n\t" // i
             "xor %%"REG_d", %%"REG_d"               \n\t" // xx
             "xorl    %%ecx, %%ecx                   \n\t" // 2*xalpha
@@ -3281,8 +3281,8 @@ static int RENAME(swScale)(SwsContext *c, uint8_t* src[], int srcStride[], int s
     }
 
 #ifdef HAVE_MMX
-    asm volatile(SFENCE:::"memory");
-    asm volatile(EMMS:::"memory");
+    __asm__ volatile(SFENCE:::"memory");
+    __asm__ volatile(EMMS:::"memory");
 #endif
     /* store changed local vars back in the context */
     c->dstY= dstY;
diff --git a/yuv2rgb.c b/yuv2rgb.c
index 83d65c5..b1f9934 100644
--- a/yuv2rgb.c
+++ b/yuv2rgb.c
@@ -613,19 +613,19 @@ SwsFunc yuv2rgb_get_func_ptr (SwsContext *c)
         }
     }
 #endif
-#ifdef HAVE_VIS
+#if HAVE_VIS != 0
     {
         SwsFunc t= yuv2rgb_init_vis(c);
         if (t) return t;
     }
 #endif
-#ifdef CONFIG_MLIB
+#if CONFIG_MLIB != 0
     {
         SwsFunc t= yuv2rgb_init_mlib(c);
         if (t) return t;
     }
 #endif
-#ifdef HAVE_ALTIVEC
+#if HAVE_ALTIVEC != 0
     if (c->flags & SWS_CPU_CAPS_ALTIVEC)
     {
         SwsFunc t = yuv2rgb_init_altivec(c);
@@ -633,7 +633,7 @@ SwsFunc yuv2rgb_get_func_ptr (SwsContext *c)
     }
 #endif
 
-#ifdef ARCH_BFIN
+#if ARCH_BFIN !=0
     if (c->flags & SWS_CPU_CAPS_BFIN)
     {
         SwsFunc t = ff_bfin_yuv2rgb_get_func_ptr (c);
diff --git a/yuv2rgb_template.c b/yuv2rgb_template.c
index 1f8e225..c86552e 100644
--- a/yuv2rgb_template.c
+++ b/yuv2rgb_template.c
@@ -133,7 +133,7 @@ static inline int RENAME(yuv420_rgb16)(SwsContext *c, uint8_t* src[], int srcStr
     h_size= (c->dstW+7)&~7;
     if(h_size*2 > FFABS(dstStride[0])) h_size-=8;
 
-    asm volatile ("pxor %mm4, %mm4;" /* zero mm4 */ );
+    __asm__ volatile ("pxor %mm4, %mm4;" /* zero mm4 */ );
     //printf("%X %X %X %X %X %X %X %X %X %X\n", (int)&c->redDither, (int)&b5Dither, (int)src[0], (int)src[1], (int)src[2], (int)dst[0],
     //srcStride[0],srcStride[1],srcStride[2],dstStride[0]);
     for (y= 0; y<srcSliceH; y++ ) {
@@ -149,7 +149,7 @@ static inline int RENAME(yuv420_rgb16)(SwsContext *c, uint8_t* src[], int srcStr
         r5Dither= ff_dither8[(y+1)&1];
         /* This MMX assembly code deals with a SINGLE scan line at a time,
          * it converts 8 pixels in each iteration. */
-        asm volatile (
+        __asm__ volatile (
         /* load data for start of next scan line */
         "movd    (%2, %0), %%mm0;" /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */
         "movd    (%3, %0), %%mm1;" /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */
@@ -211,7 +211,7 @@ YUV2RGB
         );
     }
 
-    asm volatile (EMMS);
+    __asm__ volatile (EMMS);
 
     return srcSliceH;
 }
@@ -228,7 +228,7 @@ static inline int RENAME(yuv420_rgb15)(SwsContext *c, uint8_t* src[], int srcStr
     h_size= (c->dstW+7)&~7;
     if(h_size*2 > FFABS(dstStride[0])) h_size-=8;
 
-    asm volatile ("pxor %mm4, %mm4;" /* zero mm4 */ );
+    __asm__ volatile ("pxor %mm4, %mm4;" /* zero mm4 */ );
     //printf("%X %X %X %X %X %X %X %X %X %X\n", (int)&c->redDither, (int)&b5Dither, (int)src[0], (int)src[1], (int)src[2], (int)dst[0],
     //srcStride[0],srcStride[1],srcStride[2],dstStride[0]);
     for (y= 0; y<srcSliceH; y++ ) {
@@ -244,7 +244,7 @@ static inline int RENAME(yuv420_rgb15)(SwsContext *c, uint8_t* src[], int srcStr
         r5Dither= ff_dither8[(y+1)&1];
         /* This MMX assembly code deals with a SINGLE scan line at a time,
          * it converts 8 pixels in each iteration. */
-        asm volatile (
+        __asm__ volatile (
         /* load data for start of next scan line */
         "movd    (%2, %0), %%mm0;" /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */
         "movd    (%3, %0), %%mm1;" /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */
@@ -301,7 +301,7 @@ YUV2RGB
         );
     }
 
-    asm volatile (EMMS);
+    __asm__ volatile (EMMS);
     return srcSliceH;
 }
 
@@ -317,7 +317,7 @@ static inline int RENAME(yuv420_rgb24)(SwsContext *c, uint8_t* src[], int srcStr
     h_size= (c->dstW+7)&~7;
     if(h_size*3 > FFABS(dstStride[0])) h_size-=8;
 
-    asm volatile ("pxor %mm4, %mm4;" /* zero mm4 */ );
+    __asm__ volatile ("pxor %mm4, %mm4;" /* zero mm4 */ );
 
     for (y= 0; y<srcSliceH; y++ ) {
         uint8_t *image = dst[0] + (y+srcSliceY)*dstStride[0];
@@ -328,7 +328,7 @@ static inline int RENAME(yuv420_rgb24)(SwsContext *c, uint8_t* src[], int srcStr
 
         /* This MMX assembly code deals with a SINGLE scan line at a time,
          * it converts 8 pixels in each iteration. */
-        asm volatile (
+        __asm__ volatile (
         /* load data for start of next scan line */
         "movd    (%2, %0), %%mm0;" /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */
         "movd    (%3, %0), %%mm1;" /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */
@@ -447,7 +447,7 @@ YUV2RGB
         );
     }
 
-    asm volatile (EMMS);
+    __asm__ volatile (EMMS);
     return srcSliceH;
 }
 
@@ -463,7 +463,7 @@ static inline int RENAME(yuv420_rgb32)(SwsContext *c, uint8_t* src[], int srcStr
     h_size= (c->dstW+7)&~7;
     if(h_size*4 > FFABS(dstStride[0])) h_size-=8;
 
-    asm volatile ("pxor %mm4, %mm4;" /* zero mm4 */ );
+    __asm__ volatile ("pxor %mm4, %mm4;" /* zero mm4 */ );
 
     for (y= 0; y<srcSliceH; y++ ) {
         uint8_t *image = dst[0] + (y+srcSliceY)*dstStride[0];
@@ -474,7 +474,7 @@ static inline int RENAME(yuv420_rgb32)(SwsContext *c, uint8_t* src[], int srcStr
 
         /* This MMX assembly code deals with a SINGLE scan line at a time,
          * it converts 8 pixels in each iteration. */
-        asm volatile (
+        __asm__ volatile (
         /* load data for start of next scan line */
         "movd    (%2, %0), %%mm0;" /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */
         "movd    (%3, %0), %%mm1;" /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */
@@ -533,6 +533,6 @@ YUV2RGB
         );
     }
 
-    asm volatile (EMMS);
+    __asm__ volatile (EMMS);
     return srcSliceH;
 }
diff --git a/yuv2rgb_vis.c b/yuv2rgb_vis.c
index 120fa56..42a0094 100644
--- a/yuv2rgb_vis.c
+++ b/yuv2rgb_vis.c
@@ -85,7 +85,7 @@ static int vis_420P_ARGB32(SwsContext *c, uint8_t* src[], int srcStride[], int s
   int y, out1, out2, out3, out4, out5, out6;
 
   for(y=0;y < srcSliceH;++y) {
-      asm volatile (
+      __asm__ volatile (
           YUV2RGB_INIT
           "wr %%g0, 0xd2, %%asi        \n\t" /* ASI_FL16_P */
           "1:                          \n\t"
@@ -136,7 +136,7 @@ static int vis_422P_ARGB32(SwsContext *c, uint8_t* src[], int srcStride[], int s
   int y, out1, out2, out3, out4, out5, out6;
 
   for(y=0;y < srcSliceH;++y) {
-      asm volatile (
+      __asm__ volatile (
           YUV2RGB_INIT
           "wr %%g0, 0xd2, %%asi        \n\t" /* ASI_FL16_P */
           "1:                          \n\t"
